{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDAFA7kfZr6KJYT0pRCyL0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KripaMishra/Translation/blob/main/LangChain_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82CPV1fNBLlY",
        "outputId": "e190fe2e-6bb6-4016-9c40-701d2910f4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from Langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from Langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from Langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from Langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from Langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from Langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from Langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from Langchain)\n",
            "  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from Langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from Langchain)\n",
            "  Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from Langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from Langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from Langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from Langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->Langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->Langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->Langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->Langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->Langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->Langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->Langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->Langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->Langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->Langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->Langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->Langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->Langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->Langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->Langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, Langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed Langchain-0.1.13 dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-community-0.0.29 langchain-core-0.1.36 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install Langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "i1pimn-qCg0u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] =\"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\""
      ],
      "metadata": {
        "id": "S-Qeqm8SCk2T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNbX4bbbC0Dk",
        "outputId": "7f260b82-3887-43e2-92df-be4457ab1fc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/262.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/262.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0.9)"
      ],
      "metadata": {
        "id": "03Wj6gR9Cs3f"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"tell me a joke about Banana\"\n",
        "\n"
      ],
      "metadata": {
        "id": "6tADyS6fC6zE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting\n"
      ],
      "metadata": {
        "id": "Mo23i4c-FjuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "u6JX74dXC6tD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "26Lf9lVi4WlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=PromptTemplate.from_template('Who is the first person to {input}')\n",
        "prompt.format(input='fly the concord aeroplane')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2C1ez5EUC6k7",
        "outputId": "c741b1cb-500a-4113-bbf8-a0238c977895"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Who is the first person to fly the concord aeroplane'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chaining"
      ],
      "metadata": {
        "id": "kKA64grlGY7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. One way to chain different components together is to use | symbol as follows;"
      ],
      "metadata": {
        "id": "fJGeArueGbxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCREQcfjGbDK",
        "outputId": "7d449e7b-3bb6-433d-fa09-c017ebe05444"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['input'], template='Who is the first person to {input}')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=OpenAI(temperature=0.4)"
      ],
      "metadata": {
        "id": "2d9zl3PJGbAw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "output_parser=StrOutputParser()"
      ],
      "metadata": {
        "id": "8hvdr3tLIFAi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain= prompt| model|output_parser"
      ],
      "metadata": {
        "id": "jrIlOAv_C6h-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: This method takes in a dictonary as prompt, while the LLMChain method takes in the string as prompt. In other words | method takes in prompt template which is a dictonary and the LLMChain method takes in a complete prompt which is a string.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KBu5m2ZSHKhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(input='bake a cake')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "TlhRP9cBC6fT",
        "outputId": "a343cf7e-6bc4-4592-fd8a-bb57c3428406"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'?\\n\\nThe first person to bake a cake is unknown, as the origins of cake baking can be traced back to ancient civilizations such as the Egyptians, Greeks, and Romans. However, the first recorded recipe for a cake was written by the ancient Greek poet and philosopher, Archestratus, in the 5th century BC. The recipe was for a simple honey cake made with flour, eggs, and cheese. Over time, cakes evolved and became more elaborate, with the addition of ingredients such as sugar, butter, and spices. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Another way to chain different components is to use the LLMChain method"
      ],
      "metadata": {
        "id": "bLLpr8XxJBof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "Nl5ObngCC6cL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=LLMChain(llm=llm, prompt=prompt)\n",
        "response=chain.invoke(\" walk on moon\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijqqr_9xC6ZD",
        "outputId": "275069a9-128b-48f4-c840-a33fe2081852"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': ' walk on moon', 'text': '\\n\\nNeil Armstrong was the first person to walk on the moon. He famously said \"That\\'s one small step for a man, one giant leap for mankind\" as he stepped onto the lunar surface on July 20, 1969, as part of the Apollo 11 mission.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain=LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
        "response=chain.invoke(\" walk on moon\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc-697ewC6WL",
        "outputId": "cd250023-0237-48c7-bf9a-c1cdfba2762a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWho is the first person to  walk on moon\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': ' walk on moon', 'text': '?\\n\\nThe first person to walk on the moon was American astronaut Neil Armstrong on July 21, 1969 during the Apollo 11 mission.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Sequential Chain"
      ],
      "metadata": {
        "id": "9kuFCMTQDQeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.1)\n",
        "pt1=PromptTemplate(\n",
        "    input_variables=['condition'],\n",
        "    template=' suggest me a good medicine for {condition} ?'\n",
        ")\n",
        "chain1=LLMChain(llm=llm, prompt=pt1)\n",
        "\n",
        "pt2=PromptTemplate(\n",
        "    input_variables=['medicine'],\n",
        "    template=\"what are the best brands for {medicine}  \"\n",
        ")\n",
        "chain2=LLMChain(llm=llm, prompt=pt2)"
      ],
      "metadata": {
        "id": "Tjg_kT88C6TT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain"
      ],
      "metadata": {
        "id": "pxPCHtmMC6Nz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = SimpleSequentialChain(chains = [chain1, chain2])\n",
        "\n",
        "content = chain.invoke(\"Hair loss\")\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I02fWN8MC6LL",
        "outputId": "2ae31240-b660-4f5c-8118-b8dc8c2ce799"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Hair loss', 'output': ' a doctor before taking any supplements to ensure they are safe and effective for you.\\n\\nSome popular brands for these medications include Rogaine (minoxidil), Propecia (finasteride), and Aldactone (spironolactone). However, it is important to consult with a doctor to determine the best brand and dosage for your specific needs.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Chain\n",
        "- There is a issue with SimpleSequentialChain it only shows last input information, to tackle this challenge we can use the Sequential Chain"
      ],
      "metadata": {
        "id": "jkFrzKe3F31t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=1)\n",
        "p3=PromptTemplate(\n",
        "    input_variables=['a'],\n",
        "    template=\"What comes after  {a}\"\n",
        "\n",
        ")\n",
        "chain3= LLMChain(llm=llm, prompt=p3, output_key=\"b\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L8zUFU3yC6Id"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=1)\n",
        "p4=PromptTemplate(\n",
        "    input_variables=['b'],\n",
        "    template=\"What comes after {b}\"\n",
        "\n",
        ")\n",
        "chain4= LLMChain(llm=llm, prompt=p4, output_key=\"c\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yheMCPLYINiB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [chain3, chain4],\n",
        "    input_variables = ['a'],\n",
        "    output_variables = ['b', \"c\"]\n",
        ")"
      ],
      "metadata": {
        "id": "aTl81DpFC6Fn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({\"a\": \"g\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH12isaPC6C0",
        "outputId": "97c16619-2b94-4f2d-8174-16892a708032"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 'g', 'b': 'pt\\n\\nGPT, or Generative Pre-trained Transformer, is a type of natural language processing (NLP) technology. It has been used for various applications, such as text generation, language translation, and text classification.\\n\\nThe most recent version of GPT is GPT-3, which was released in 2020. It has a significantly larger model and training dataset compared to its predecessors, making it capable of performing a wider range of tasks and generating more human-like text.\\n\\nAs of now, there is no official announcement for what will come after GPT-3. However, researchers and companies are constantly working on developing new and improved NLP models and techniques. It is possible that a new, more advanced version of GPT or a completely different NLP technology will be developed in the future.', 'c': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents and Tools"
      ],
      "metadata": {
        "id": "hqCHmmOKLOgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6NZ0VqGC5_7",
        "outputId": "47b5aca2-5d86-4bee-df1a-7de6c478236d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=d2169b0478339ef65cfb3665f376654801818691517011091e53305519b8ee11\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "tmE7lU95C59D"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['SERPAPI_API_KEY']= userdata.get('SERPAPI_API_KEY')"
      ],
      "metadata": {
        "id": "8Dguq6PsC56L"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools"
      ],
      "metadata": {
        "id": "87S_-xUsC528"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "TnrXVDsSC5y1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "#Google Search API\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"When is the next wrestlemania\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "rSgBiC5gC5s8",
        "outputId": "0dc8b0eb-f67d-4abb-d2f8-4358e2686202"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer\n",
            "Action: Search\n",
            "Action Input: \"next wrestlemania\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSat, Apr 6, 2024, 7:00 PM – Sun, Apr 7, 2024\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should double check the date and time\n",
            "Action: Search\n",
            "Action Input: \"wrestlemania 2024 date and time\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSat, Apr 6, 2024, 7:00 PM – Sun, Apr 7, 2024\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The next Wrestlemania will be held on April 6-7, 2024 at 7:00 PM.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The next Wrestlemania will be held on April 6-7, 2024 at 7:00 PM.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wikipedia and llm-math tool"
      ],
      "metadata": {
        "id": "oTyGwUGo8RLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0w1PrnNC5qD",
        "outputId": "de628494-623e-4210-840b-a6cfcba8938f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=1b10328d18083cc7938750a90d5fe1feb20cc042fd6344527c373a75dbb0311c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "agent.run(\"who was joseph stalin?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "d0LyU5LkC5ks",
        "outputId": "9496088e-68ad-4599-da5e-3b87bcc60adf"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use wikipedia to find information about Joseph Stalin\n",
            "Action: wikipedia\n",
            "Action Input: Joseph Stalin\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: Joseph Stalin\n",
            "Summary: Joseph Vissarionovich Stalin (born Ioseb Besarionis dze Jughashvili; 18 December [O.S. 6 December] 1878 – 5 March 1953) was a Soviet revolutionary and politician who was the longest-serving leader of the Soviet Union from 1924 until his death in 1953. He held power as General Secretary of the Communist Party of the Soviet Union (1922–1952) and Chairman of the Council of Ministers of the Soviet Union (1941–1953). Stalin initially governed the country as part of a collective leadership before consolidating power to become a dictator by the 1930s. Stalin coined the term Marxism–Leninism to outline his Leninist interpretation of Marxism, also known as Stalinism.\n",
            "Born into a poor family in Gori in what was then the Russian Empire, Stalin attended the Tbilisi Spiritual Seminary before joining the Marxist Russian Social Democratic Labour Party. He edited the party's newspaper, Pravda, and raised funds for Vladimir Lenin's Bolshevik faction via robberies, kidnappings and protection rackets. Repeatedly arrested, he underwent several internal exiles to Siberia. After the Bolsheviks seized power in the October Revolution and created a one-party state under the new Communist Party in 1917, Stalin joined its governing Politburo. Serving in the Russian Civil War before overseeing the Soviet Union's establishment in 1922, Stalin assumed leadership over the country following Lenin's death in 1924. Under Stalin, socialism in one country became a central tenet of the party's ideology. As a result of his Five-Year Plans, the country underwent agricultural collectivisation and rapid industrialisation, creating a centralised command economy. Severe disruptions to food production contributed to the famine of 1930–33, including the Asharshylyk in Kazakhstan and the Holodomor in Ukraine. To eradicate those deemed \"enemies of the working class\", Stalin instituted the Great Purge, in which over a million were imprisoned, largely in the Gulag system of forced labour camps, and at least 700,000 executed between 1934 and 1939. By 1937, he had absolute control over the party and government.\n",
            "Stalin promoted Marxism–Leninism abroad through the Communist International and supported European anti-fascist movements during the 1930s, particularly in the Spanish Civil War. In 1939, his regime signed a non-aggression pact with Nazi Germany, resulting in the Soviet invasion of Poland. Germany ended the pact by invading the Soviet Union in 1941. Despite initial catastrophes, the Soviet Red Army repelled the German invasion and captured Berlin in 1945, ending World War II in Europe. Amid the war, the Soviets annexed the Baltic states and Bessarabia and North Bukovina, subsequently establishing Soviet-aligned governments throughout Central and Eastern Europe and in parts of East Asia. The Soviet Union and the United States emerged as global superpowers and entered a period of tension, the Cold War. Stalin presided over the Soviet post-war reconstruction and its development of an atomic bomb in 1949. During these years, the country experienced another major famine and an antisemitic campaign that culminated in the doctors' plot. After Stalin's death in 1953, he was eventually succeeded by Nikita Khrushchev, who subsequently denounced his rule and initiated the de-Stalinisation of Soviet society.\n",
            "Widely considered to be one of the 20th century's most significant figures, Stalin was the subject of a pervasive personality cult within the international Marxist–Leninist movement, which revered him as a champion of the working class and socialism. Since the dissolution of the Soviet Union in 1991, Stalin has retained popularity in Russia and Georgia as a victorious wartime leader who cemented the Soviet Union's status as a leading world power. Conversely, his totalitarian regime has been widely condemned for overseeing mass repression, ethnic cleansing, pervasive censorship, wide-scale deportation, hundreds of thousands of executions, and famines\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know more about Joseph Stalin and his impact on the Soviet Union and the world\n",
            "Final Answer: Joseph Stalin was a Soviet revolutionary and politician who served as the leader of the Soviet Union from 1924 until his death in 1953. He is known for his brutal regime, which included the Great Purge and the implementation of a command economy. Despite this, he is still revered by some as a champion of the working class and socialism.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Joseph Stalin was a Soviet revolutionary and politician who served as the leader of the Soviet Union from 1924 until his death in 1953. He is known for his brutal regime, which included the Great Purge and the implementation of a command economy. Despite this, he is still revered by some as a champion of the working class and socialism.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConversationBufferMemory\n",
        "We want the chat applicatoin to have some sort of memory so that it can remember the context of the current chat"
      ],
      "metadata": {
        "id": "hbJIPCGJ9BGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)"
      ],
      "metadata": {
        "id": "ly6DNRAU9foT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['pokemon type'],\n",
        "    template = \" tell me a legendary pokemon of {pokemon type}\"\n",
        ")"
      ],
      "metadata": {
        "id": "j5E9TlBA9gsR"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "name = chain.run(\"Fire\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psSocOuJ9gpu",
        "outputId": "da25c328-66c8-4a1b-cd0e-fda5e64f5bc5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Moltres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTPG3V849gl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory=ConversationBufferMemory()\n",
        "\n",
        "chain=LLMChain(llm=llm,prompt=prompt_template_name, memory=memory )\n",
        "name=chain.run(\"Water\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxSU4S8nC5iM",
        "outputId": "ab0ff1f6-3120-4367-a9be-a82cff319d92"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " type\n",
            "\n",
            "Suicune \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name=chain.run('Normal')"
      ],
      "metadata": {
        "id": "8Qd166WEC5fr"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZJS2ODJ-T8B",
        "outputId": "e8988280-2a74-4f5a-82f7-34692c459626"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " type and explain why it is considered legendary\n",
            "\n",
            "One example of a legendary Normal type Pokemon is Arceus. Arceus is known as the \"Alpha Pokemon\" and is said to be the creator of the Pokemon world. It is said to have created the universe with its 1000 arms and has the power to control time and space.\n",
            "\n",
            "In addition, Arceus is the only known Pokemon that can change its type by holding different plates, making it incredibly versatile and powerful in battle. Its sheer power and ability to shape the world around it have solidified its status as a legendary Pokemon.\n",
            "\n",
            "Furthermore, in the Pokemon lore, Arceus is said to have existed before any other Pokemon and its very existence is shrouded in mystery, adding to its legendary status. Its rarity in the games also makes it highly sought after by trainers.\n",
            "\n",
            "Overall, Arceus' unique powers, role in creation, and mysterious origins make it a legendary Pokemon and a symbol of immense power and significance in the Pokemon world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPxjIwJJC5aF",
        "outputId": "2b6f7c6b-87c8-4367-fee2-791296142104"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Water\n",
            "AI:  type\n",
            "\n",
            "Suicune \n",
            "Human: Normal\n",
            "AI:  type and explain why it is considered legendary\n",
            "\n",
            "One example of a legendary Normal type Pokemon is Arceus. Arceus is known as the \"Alpha Pokemon\" and is said to be the creator of the Pokemon world. It is said to have created the universe with its 1000 arms and has the power to control time and space.\n",
            "\n",
            "In addition, Arceus is the only known Pokemon that can change its type by holding different plates, making it incredibly versatile and powerful in battle. Its sheer power and ability to shape the world around it have solidified its status as a legendary Pokemon.\n",
            "\n",
            "Furthermore, in the Pokemon lore, Arceus is said to have existed before any other Pokemon and its very existence is shrouded in mystery, adding to its legendary status. Its rarity in the games also makes it highly sought after by trainers.\n",
            "\n",
            "Overall, Arceus' unique powers, role in creation, and mysterious origins make it a legendary Pokemon and a symbol of immense power and significance in the Pokemon world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConversationChain\n",
        "Conversation buffer memory goes growing endlessly\n",
        "\n",
        "Just remember last 5 Conversation Chain\n",
        "\n",
        "Just remember last 10-20 Conversation Chain"
      ],
      "metadata": {
        "id": "iQEDHZM-F3-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "v4OkbYZfC5U7"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo=ConversationChain(llm=OpenAI(temperature=0.2))\n",
        "print(convo.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsW-UYSE7Z6U",
        "outputId": "a4d4cba4-7934-4a0b-d6ef-2b89fc3a73f1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"what is the difference betweeen run and invoke method of Langchain\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "OXWIR5iW7Z3o",
        "outputId": "e8a6b41e-25e2-48df-e375-7387874e987d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The run method in Langchain is used to execute a specific code or program, while the invoke method is used to call a function or method within that code or program. Essentially, the run method is used to start the execution of the code, while the invoke method is used to trigger a specific action within that code. Additionally, the run method typically runs the entire code or program, while the invoke method can be used to call specific functions or methods within the code. Does that answer your question?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"can i use the run and inovke methods interchangably?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "TJ7fNHRl7Z0w",
        "outputId": "21c5a333-c7f0-4026-f7ab-1be9a1902213"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' No, the run and invoke methods serve different purposes and cannot be used interchangeably. The run method is used to start the execution of the code, while the invoke method is used to call specific functions or methods within the code. Using them interchangeably could result in errors or unexpected behavior.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"tell me a fact about apple\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "SiQNYKfV7Zxw",
        "outputId": "9e4e0d8f-68c7-4bdd-cfa8-f3ba5d34a998"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Did you know that apples are a member of the rose family? They are also made up of 25% air, which is why they float in water. Additionally, apples are a great source of fiber and vitamin C.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrct6mk_7ZvA",
        "outputId": "130d1b8e-80c8-48f8-dccc-74e472241eb6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: what is the difference betweeen run and invoke method of Langchain\n",
            "AI:  The run method in Langchain is used to execute a specific code or program, while the invoke method is used to call a function or method within that code or program. Essentially, the run method is used to start the execution of the code, while the invoke method is used to trigger a specific action within that code. Additionally, the run method typically runs the entire code or program, while the invoke method can be used to call specific functions or methods within the code. Does that answer your question?\n",
            "Human: can i use the run and inovke methods interchangably?\n",
            "AI:  No, the run and invoke methods serve different purposes and cannot be used interchangeably. The run method is used to start the execution of the code, while the invoke method is used to call specific functions or methods within the code. Using them interchangeably could result in errors or unexpected behavior.\n",
            "Human: tell me a joke about skinny apple\n",
            "AI:  I'm sorry, I do not have the capability to generate jokes. My purpose is to provide information and assist with tasks. Is there something else I can help you with?\n",
            "Human: tell me a fact about apple\n",
            "AI:  Did you know that apples are a member of the rose family? They are also made up of 25% air, which is why they float in water. Additionally, apples are a great source of fiber and vitamin C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "00CB4tTT7ZsZ",
        "outputId": "baaf1846-aeb4-4dea-fd56-03fff2995c20"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first cricket world cup was won by the West Indies in 1975. The final match was played between the West Indies and Australia at Lord\\'s Cricket Ground in London, England. The West Indies team, led by Clive Lloyd, won by 17 runs. Interestingly, the first cricket world cup was not officially called the \"World Cup\" at the time. It was known as the \"Prudential Cup\" after its sponsor, the Prudential Assurance Company.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3iyFMUbH7Znd",
        "outputId": "73b0bbab-3876-4aa0-d2d0-c018b356498e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 5+5 is equal to 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6yApfW5A7Zk0",
        "outputId": "5349c1fd-defc-44fe-8dc1-cf6bbb71d476"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I am not sure which team you are referring to. Can you provide more context?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we set the k value to 1 the application will remember only the last command from convo"
      ],
      "metadata": {
        "id": "j26kADZPH-5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0wHgdxO7ZiG",
        "outputId": "873a1138-2b35-479d-890a-66a308a3a81c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who was the captain of the winning team?\n",
            "AI:  I am not sure which team you are referring to. Can you provide more context?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlwJkTcY7ZfQ",
        "outputId": "6c8b680c-0c7c-42d3-fc5a-c980c7f0f884"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/286.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/286.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/updated.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "lrZCvkKq7Zcx"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4EPmcKr7ZaJ",
        "outputId": "273b8487-d198-4a0a-c8d6-75d60a494e18"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='KRIPA SHANKAR MISHRA \\nData Scientist \\nPhase-5 Aya Nagar, New Delhi | 8178352574 | kripa5661@gmail.com | LinkedIn | Github\\nSUMMARY:\\nEager and motivated Data Science enthusiast with a robust foundation in statistical analysis,\\nmachine learning, and programming, possessing a comprehensive skill set and well-versed in\\nprofessional tools, ready to apply this knowledge towards developing and implementing end-\\nto-end projects. Adept at utilizing data science concepts to solve real-world problems, with a\\nkeen focus on leveraging analytical skills to derive meaningful insights\\nVlippr\\nData Scientist intern | January, 2024 - Present\\nResearching and finetuning machine learning models for audio tasks, such as speech\\nrecognition, Language detection, or audio anomaly detection. .\\nPre-processing and cleaning audio data for model training, including techniques like noise\\nreduction, silence removal, and feature extraction.\\nEvaluation and optimization of audio models using relevant metrics and visualization\\ntechniques, ensuring their performance aligns with product requirements.\\nIn the capacity of a Data Scientist, my role is the development of essential project\\ndocumentation. This encompasses crafting comprehensive High-Level Design (HLD)\\ndocuments that furnish an overarching view of the project architecture.\\nCollaboration with MLOps team for testing and deployment of services. \\nDeveloped and executed a comprehensive end-to-end project leveraging machine learning\\nalgorithms to automate the categorization of customer complaints based on their severity\\nlevels. This initiative aimed to enhance the efficiency of the complaint management\\nprocess.\\nUtilized PySpark, MongoDB, and Apache Airflow for orchestrating data processing\\nworkflows and scheduling tasks, ensuring seamless integration and streamlined execution\\nof the machine learning pipeline.\\nImplemented containerization and cloud hosting strategies by harnessing the power of\\nDocker and Amazon Web Services (AWS). This approach facilitated the deployment and\\nscaling of the classification model, ensuring accessibility and reliability in a cloud-based\\nenvironment\\nDesigned and implemented a robust sensor fault detection system capable of identifying\\nand diagnosing any potential sensor failure in a diverse range of applications, using an end-\\nto-end data pipeline on Confluent Kafka and MongoDB, to ensure seamless data ingestion,\\nprocessing, and storage.\\nUtilized GitHub Actions for the automation of CI/CD pipelines. \\nEnsured accessibility and ease of integration by exposing the fault detection model as an\\nAPI using FastAPI, enabling developers and applications to effortlessly incorporate sensor\\nfault detection capabilities into their systems Finance Complaint Classifier\\nSensor Fault Detection ProjectWORK EXPERIENCE:\\nPROJECTS:', metadata={'source': '/content/updated.pdf', 'page': 0}),\n",
              " Document(page_content=\"Programming Languages: Python, Pyspark, SQL, NoSQL.\\nDatabases: MySQL, MongoDB, PostgreSQL. \\nPython packages and Frameworks: NumPy, Pandas, SciPy, Scikit-learn, Beautiful Soup,\\nMatplotlib, Seaborn, Flask, HTML.\\nCI/CD Tools: GitHub Actions, CircleCI, Jenkins.\\nPackaging and Orchestration: Docker, Kubernetes. \\nCloud Platform: AWS, Azure. \\nLLM Framework: LangChain, LlamaIndex, Chainlit. \\nVector Database: SQLite, Pinecone, Weviate.SKILLS:Bachelor of Arts - Economics and Mathematics2020 - 2023 | Shaheed Bhagat Singh College, Delhi University.EDUCATION:Chicken Disease Classifier Project\\nDeveloped an end-to-end Deep Learning Model to classify Chicken Diseases using fecal\\nimages, addressing a crucial aspect of poultry health monitoring. \\nEngineered and pre-processed the dataset, incorporating Transfer Learning techniques to\\nleverage pre-trained neural network architectures, significantly reducing the need for\\nextensive training data and accelerating model convergence.\\nImplemented a comprehensive evaluation process, involving cross-validation and\\nperformance metrics analysis, to validate the model's reliability and effectiveness in real-\\nworld disease detection scenarios.\\nCOURSES:\\nDeployment of Machine Learning Models | Udemy\\nThe Complete SQL Bootcamp: Go from Zero to Hero | Udemy\\nThe Data Science Course: Complete Data Science Bootcamp 2024 | Udemy\\nFundamentals of Data Visualization in Tableau | Udemy\\nHOBBIES:\\nReading books\\nSports\\nTeaching\", metadata={'source': '/content/updated.pdf', 'page': 1})]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PlUm8nX7ZXZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}